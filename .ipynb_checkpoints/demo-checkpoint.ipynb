{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import os \n",
    "import scipy.ndimage as nd\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "\n",
    "from networks.baseline import Res_Deeplab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Define color map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(num_cls):\n",
    "    \"\"\" Returns the color map for visualizing the segmentation mask.\n",
    "    Args:\n",
    "        num_cls: Number of classes\n",
    "    Returns:\n",
    "        The color map\n",
    "    \"\"\"\n",
    "\n",
    "    n = num_cls\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "palette = get_palette(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select GPU environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Res_Deeplab(num_classes=40)\n",
    "saved_state_dict = torch.load('dataset/model.pth')\n",
    "model.load_state_dict(saved_state_dict)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read prepocess Image and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('image/1.jpg')\n",
    "depth = Image.open('image/1_depth.png')\n",
    "\n",
    "img = np.array(img).astype(np.float32)\n",
    "img = (img - np.asarray([122.675,116.669,104.008]))[:,:,::-1]\n",
    "img = np.array(img).astype(np.float32).transpose((2, 0, 1))[np.newaxis, ...]\n",
    "img = torch.from_numpy(img).float()\n",
    "\n",
    "## convert depth to xyz\n",
    "depth = np.array(depth).astype(np.float32)\n",
    "depth = depth[np.newaxis, ...]\n",
    "_, h,w = depth.shape\n",
    "z = depth\n",
    "xx, yy = np.meshgrid(np.array(range(w))+1, np.array(range(h))+1)\n",
    "fx_rgb = 5.18857e+02 * scale_x\n",
    "fy_rgb = 5.19469e+02 * scale_y\n",
    "cx_rgb = w / 2.0\n",
    "cy_rgb = h / 2.0\n",
    "C = np.array([[fx_rgb, 0, cx_rgb], [0, fy_rgb, cy_rgb], [0, 0, 1]])\n",
    "cc_rgb = C[0:2, 2]\n",
    "fc_rgb = np.diag(C[0:2, 0:2])\n",
    "x = (np.multiply((xx - cc_rgb[0]), z) / fc_rgb[0])\n",
    "y = (np.multiply((yy - cc_rgb[1]), z) / fc_rgb[1])\n",
    "depth = np.concatenate([x, y, z], axis=0)[np.newaxis, ...]\n",
    "depth = torch.from_numpy(depth).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Forward and output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(img, depth, depth)\n",
    "pred = np.asarray(np.argmax(pred.cpu().numpy()[0, ...], axis=0), dtype=np.uint8)\n",
    "pred_img = PILImage.fromarray(pred)\n",
    "pred_img.save('image/result.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
